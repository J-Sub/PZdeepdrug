{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import AUROC, Accuracy, Precision, Recall\n",
    "from torchmetrics.classification import BinaryAUROC, BinaryF1Score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "import pickle\n",
    "from load_msi_data import LoadData\n",
    "from model import CombNet, CombNetSupCon\n",
    "from dataset import CombinationDataset\n",
    "from loss import SupConLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/processed/C_DCDB_neg1_dup0_ddi0_None_seed42.pt already exists in processed/ directory.\n",
      "Loading dataset...data/processed/C_DCDB_neg1_dup0_ddi0_None_seed42.pt\n",
      "8442\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "argument of CombinationDataset\n",
    "- database: str, default='C_DCDB' ['C_DCDB', 'DCDB', 'DC_combined']\n",
    "- neg_ratio: int, default=1\n",
    "- duplicate: bool, default=False (if True, duplicate each samples) -> [a, b] & [b, a]\n",
    "- use_ddi: bool, default=False (if True, use ddi dataset)\n",
    "- ddi_dataset: str, default=None (if use_ddi is True, choose ddi dataset) ['DB', 'TWOSIDES']\n",
    "- seed: int, default=42\n",
    "'''\n",
    "# without ddi\n",
    "dataset = CombinationDataset(database='C_DCDB', neg_ratio=1, duplicate=False, seed=SEED)\n",
    "print(len(dataset))\n",
    "\n",
    "# with ddi\n",
    "# dataset = CombinationDataset(database='C_DCDB', neg_ratio=1, duplicate=False, use_ddi=True, ddi_dataset='DB', seed=SEED)\n",
    "# print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cross_entropy(model, device, train_loader, criterion, optimizer, metric_list=[accuracy_score]):\n",
    "\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    target_list = []\n",
    "    pred_list = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data).view(-1) # z\n",
    "        # print(output)\n",
    "        loss = criterion(output, target) # z, y\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        pred_list.append(torch.sigmoid(output).detach().cpu().numpy())\n",
    "        target_list.append(target.long().detach().cpu().numpy())\n",
    "    \n",
    "    # metric\n",
    "    scores = []\n",
    "    for metric in metric_list:\n",
    "        if (metric == roc_auc_score) or (metric == average_precision_score):\n",
    "            scores.append(metric(np.concatenate(target_list), np.concatenate(pred_list)))\n",
    "        else: # accuracy_score, f1_score, precision_score, recall_score\n",
    "            scores.append(metric(np.concatenate(target_list), np.concatenate(pred_list).round()))\n",
    "    \n",
    "    return train_loss / (batch_idx + 1), scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device, loader, criterion, metric_list=[accuracy_score], checkpoint=None):\n",
    "    # evaluate\n",
    "    if checkpoint is not None:\n",
    "        model.load_state_dict(torch.load(checkpoint))\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "\n",
    "    target_list = []\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            data, target = data.to(device), target.float().to(device)\n",
    "            output = model(data).view(-1)\n",
    "            eval_loss += criterion(output, target).item()\n",
    "            pred_list.append(torch.sigmoid(output).detach().cpu().numpy())\n",
    "            target_list.append(target.long().detach().cpu().numpy())\n",
    "\n",
    "    scores = []\n",
    "    for metric in metric_list:\n",
    "        if (metric == roc_auc_score) or (metric == average_precision_score):\n",
    "            scores.append(metric(np.concatenate(target_list), np.concatenate(pred_list)))\n",
    "        else: # accuracy_score, f1_score, precision_score, recall_score\n",
    "            scores.append(metric(np.concatenate(target_list), np.concatenate(pred_list).round()))\n",
    "    return eval_loss / (batch_idx + 1), scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    input_dim = dataset[0][0].shape[0]\n",
    "    hidden_dim = input_dim\n",
    "    output_dim = 1\n",
    "    print('input_dim: {}, hidden_dim: {}, output_dim: {}'.format(input_dim, hidden_dim, output_dim))\n",
    "    model = CombNet(input_dim, hidden_dim, output_dim, comb_type='cat')\n",
    "\n",
    "    EPOCHS = 100\n",
    "    LR = 0.001\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_scores = train_cross_entropy(model, device, train_loader, criterion, optimizer, metric_list=[accuracy_score, roc_auc_score, f1_score, average_precision_score])\n",
    "        valid_loss, valid_scores = evaluate(model, device, valid_loader, criterion, metric_list=[accuracy_score, roc_auc_score, f1_score, average_precision_score])\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        print(f'Epoch {epoch+1:03d}: | Train Loss: {train_loss:.4f} | Train Acc: {train_scores[0]*100:.2f}% | Train AUROC: {train_scores[1]:.2f} | Train F1: {train_scores[2]:.4f} | Train AUPRC: {train_scores[3]:.2f} || Val. Loss: {valid_loss:.4f} | Val. Acc: {valid_scores[0]*100:.2f}% | Val. AUROC: {valid_scores[1]:.2f} | Val. F1: {valid_scores[2]:.4f} | Val. AUPRC: {valid_scores[3]:.2f}')\n",
    "    \n",
    "    test_loss, test_scores = evaluate(model, device, test_loader, criterion, metric_list=[accuracy_score, roc_auc_score, f1_score, average_precision_score], checkpoint='checkpoint.pt')\n",
    "    print(f'Test Loss: {test_loss:.4f} | Test Acc: {test_scores[0]*100:.2f}% | Test AUROC: {test_scores[1]:.2f} | Test F1: {test_scores[2]:.4f} | Test AUPRC: {test_scores[3]:.2f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim: 256, hidden_dim: 256, output_dim: 1\n",
      "Epoch 001: | Train Loss: 0.5871 | Train Acc: 68.31% | Train AUROC: 0.75 | Train F1: 0.6794 | Train AUPRC: 0.77 || Val. Loss: 0.5182 | Val. Acc: 74.17% | Val. AUROC: 0.82 | Val. F1: 0.7500 | Val. AUPRC: 0.83\n",
      "Epoch 002: | Train Loss: 0.4699 | Train Acc: 77.73% | Train AUROC: 0.86 | Train F1: 0.7726 | Train AUPRC: 0.86 || Val. Loss: 0.4685 | Val. Acc: 76.90% | Val. AUROC: 0.86 | Val. F1: 0.7659 | Val. AUPRC: 0.87\n",
      "Epoch 003: | Train Loss: 0.4255 | Train Acc: 80.97% | Train AUROC: 0.89 | Train F1: 0.8078 | Train AUPRC: 0.89 || Val. Loss: 0.4758 | Val. Acc: 76.18% | Val. AUROC: 0.87 | Val. F1: 0.7754 | Val. AUPRC: 0.88\n",
      "Epoch 004: | Train Loss: 0.3801 | Train Acc: 83.23% | Train AUROC: 0.91 | Train F1: 0.8315 | Train AUPRC: 0.91 || Val. Loss: 0.4861 | Val. Acc: 77.96% | Val. AUROC: 0.87 | Val. F1: 0.7956 | Val. AUPRC: 0.87\n",
      "Epoch 005: | Train Loss: 0.3546 | Train Acc: 84.20% | Train AUROC: 0.92 | Train F1: 0.8415 | Train AUPRC: 0.92 || Val. Loss: 0.4593 | Val. Acc: 79.38% | Val. AUROC: 0.87 | Val. F1: 0.7981 | Val. AUPRC: 0.87\n",
      "Epoch 006: | Train Loss: 0.3354 | Train Acc: 85.57% | Train AUROC: 0.93 | Train F1: 0.8553 | Train AUPRC: 0.93 || Val. Loss: 0.4516 | Val. Acc: 79.03% | Val. AUROC: 0.88 | Val. F1: 0.8000 | Val. AUPRC: 0.88\n",
      "Epoch 007: | Train Loss: 0.3086 | Train Acc: 86.49% | Train AUROC: 0.94 | Train F1: 0.8643 | Train AUPRC: 0.94 || Val. Loss: 0.4667 | Val. Acc: 80.21% | Val. AUROC: 0.88 | Val. F1: 0.8096 | Val. AUPRC: 0.87\n",
      "Epoch 008: | Train Loss: 0.2814 | Train Acc: 88.12% | Train AUROC: 0.95 | Train F1: 0.8813 | Train AUPRC: 0.95 || Val. Loss: 0.4667 | Val. Acc: 79.27% | Val. AUROC: 0.88 | Val. F1: 0.8023 | Val. AUPRC: 0.89\n",
      "Epoch 009: | Train Loss: 0.2595 | Train Acc: 89.31% | Train AUROC: 0.96 | Train F1: 0.8929 | Train AUPRC: 0.96 || Val. Loss: 0.4928 | Val. Acc: 79.62% | Val. AUROC: 0.88 | Val. F1: 0.8018 | Val. AUPRC: 0.87\n",
      "Epoch 010: | Train Loss: 0.2451 | Train Acc: 89.71% | Train AUROC: 0.96 | Train F1: 0.8972 | Train AUPRC: 0.97 || Val. Loss: 0.5506 | Val. Acc: 77.61% | Val. AUROC: 0.88 | Val. F1: 0.7987 | Val. AUPRC: 0.88\n",
      "Epoch 011: | Train Loss: 0.2357 | Train Acc: 90.17% | Train AUROC: 0.97 | Train F1: 0.9017 | Train AUPRC: 0.97 || Val. Loss: 0.4711 | Val. Acc: 80.81% | Val. AUROC: 0.89 | Val. F1: 0.8107 | Val. AUPRC: 0.88\n",
      "Epoch 012: | Train Loss: 0.2169 | Train Acc: 91.25% | Train AUROC: 0.97 | Train F1: 0.9124 | Train AUPRC: 0.97 || Val. Loss: 0.5002 | Val. Acc: 80.21% | Val. AUROC: 0.89 | Val. F1: 0.8087 | Val. AUPRC: 0.88\n",
      "Epoch 013: | Train Loss: 0.2050 | Train Acc: 91.75% | Train AUROC: 0.97 | Train F1: 0.9177 | Train AUPRC: 0.98 || Val. Loss: 0.5371 | Val. Acc: 79.50% | Val. AUROC: 0.89 | Val. F1: 0.8076 | Val. AUPRC: 0.89\n",
      "Epoch 014: | Train Loss: 0.1886 | Train Acc: 92.73% | Train AUROC: 0.98 | Train F1: 0.9274 | Train AUPRC: 0.98 || Val. Loss: 0.5070 | Val. Acc: 80.57% | Val. AUROC: 0.89 | Val. F1: 0.8061 | Val. AUPRC: 0.89\n",
      "Epoch 015: | Train Loss: 0.1733 | Train Acc: 93.20% | Train AUROC: 0.98 | Train F1: 0.9320 | Train AUPRC: 0.98 || Val. Loss: 0.5495 | Val. Acc: 79.62% | Val. AUROC: 0.89 | Val. F1: 0.8045 | Val. AUPRC: 0.89\n",
      "Epoch 016: | Train Loss: 0.1730 | Train Acc: 93.35% | Train AUROC: 0.98 | Train F1: 0.9336 | Train AUPRC: 0.98 || Val. Loss: 0.5576 | Val. Acc: 80.92% | Val. AUROC: 0.88 | Val. F1: 0.8126 | Val. AUPRC: 0.87\n",
      "Epoch 017: | Train Loss: 0.1544 | Train Acc: 94.21% | Train AUROC: 0.99 | Train F1: 0.9422 | Train AUPRC: 0.99 || Val. Loss: 0.5722 | Val. Acc: 79.38% | Val. AUROC: 0.89 | Val. F1: 0.8054 | Val. AUPRC: 0.88\n",
      "Epoch 018: | Train Loss: 0.1462 | Train Acc: 94.39% | Train AUROC: 0.99 | Train F1: 0.9439 | Train AUPRC: 0.99 || Val. Loss: 0.5215 | Val. Acc: 81.40% | Val. AUROC: 0.89 | Val. F1: 0.8155 | Val. AUPRC: 0.88\n",
      "Epoch 019: | Train Loss: 0.1393 | Train Acc: 94.70% | Train AUROC: 0.99 | Train F1: 0.9470 | Train AUPRC: 0.99 || Val. Loss: 0.5653 | Val. Acc: 79.15% | Val. AUROC: 0.88 | Val. F1: 0.7972 | Val. AUPRC: 0.88\n",
      "Epoch 020: | Train Loss: 0.1270 | Train Acc: 95.11% | Train AUROC: 0.99 | Train F1: 0.9513 | Train AUPRC: 0.99 || Val. Loss: 0.6065 | Val. Acc: 80.09% | Val. AUROC: 0.88 | Val. F1: 0.8073 | Val. AUPRC: 0.87\n",
      "Epoch 021: | Train Loss: 0.1322 | Train Acc: 94.88% | Train AUROC: 0.99 | Train F1: 0.9487 | Train AUPRC: 0.99 || Val. Loss: 0.5794 | Val. Acc: 80.09% | Val. AUROC: 0.89 | Val. F1: 0.8051 | Val. AUPRC: 0.89\n",
      "Epoch 022: | Train Loss: 0.1244 | Train Acc: 95.57% | Train AUROC: 0.99 | Train F1: 0.9557 | Train AUPRC: 0.99 || Val. Loss: 0.5876 | Val. Acc: 80.45% | Val. AUROC: 0.89 | Val. F1: 0.8123 | Val. AUPRC: 0.88\n",
      "Epoch 023: | Train Loss: 0.1201 | Train Acc: 95.66% | Train AUROC: 0.99 | Train F1: 0.9566 | Train AUPRC: 0.99 || Val. Loss: 0.6255 | Val. Acc: 78.91% | Val. AUROC: 0.89 | Val. F1: 0.8053 | Val. AUPRC: 0.89\n",
      "Epoch 024: | Train Loss: 0.1141 | Train Acc: 95.94% | Train AUROC: 0.99 | Train F1: 0.9595 | Train AUPRC: 0.99 || Val. Loss: 0.6289 | Val. Acc: 79.03% | Val. AUROC: 0.88 | Val. F1: 0.7973 | Val. AUPRC: 0.88\n",
      "Epoch 025: | Train Loss: 0.1030 | Train Acc: 95.99% | Train AUROC: 0.99 | Train F1: 0.9599 | Train AUPRC: 0.99 || Val. Loss: 0.6138 | Val. Acc: 80.69% | Val. AUROC: 0.89 | Val. F1: 0.8141 | Val. AUPRC: 0.88\n",
      "Epoch 026: | Train Loss: 0.0999 | Train Acc: 96.64% | Train AUROC: 0.99 | Train F1: 0.9663 | Train AUPRC: 0.99 || Val. Loss: 0.7012 | Val. Acc: 80.33% | Val. AUROC: 0.88 | Val. F1: 0.8147 | Val. AUPRC: 0.87\n",
      "Epoch 027: | Train Loss: 0.1031 | Train Acc: 96.06% | Train AUROC: 0.99 | Train F1: 0.9606 | Train AUPRC: 0.99 || Val. Loss: 0.6483 | Val. Acc: 80.21% | Val. AUROC: 0.89 | Val. F1: 0.8060 | Val. AUPRC: 0.88\n",
      "Epoch 028: | Train Loss: 0.0968 | Train Acc: 96.42% | Train AUROC: 0.99 | Train F1: 0.9642 | Train AUPRC: 0.99 || Val. Loss: 0.6724 | Val. Acc: 79.74% | Val. AUROC: 0.88 | Val. F1: 0.8041 | Val. AUPRC: 0.88\n",
      "Epoch 029: | Train Loss: 0.0900 | Train Acc: 96.59% | Train AUROC: 1.00 | Train F1: 0.9660 | Train AUPRC: 1.00 || Val. Loss: 0.6879 | Val. Acc: 80.57% | Val. AUROC: 0.88 | Val. F1: 0.8084 | Val. AUPRC: 0.88\n",
      "Epoch 030: | Train Loss: 0.0924 | Train Acc: 96.53% | Train AUROC: 0.99 | Train F1: 0.9654 | Train AUPRC: 0.99 || Val. Loss: 0.6959 | Val. Acc: 80.69% | Val. AUROC: 0.89 | Val. F1: 0.8120 | Val. AUPRC: 0.88\n",
      "Epoch 031: | Train Loss: 0.0864 | Train Acc: 96.86% | Train AUROC: 1.00 | Train F1: 0.9686 | Train AUPRC: 1.00 || Val. Loss: 0.6266 | Val. Acc: 81.87% | Val. AUROC: 0.89 | Val. F1: 0.8163 | Val. AUPRC: 0.88\n",
      "Epoch 032: | Train Loss: 0.0994 | Train Acc: 96.48% | Train AUROC: 0.99 | Train F1: 0.9649 | Train AUPRC: 0.99 || Val. Loss: 0.7014 | Val. Acc: 78.67% | Val. AUROC: 0.89 | Val. F1: 0.7955 | Val. AUPRC: 0.89\n",
      "Epoch 033: | Train Loss: 0.0828 | Train Acc: 96.83% | Train AUROC: 1.00 | Train F1: 0.9683 | Train AUPRC: 1.00 || Val. Loss: 0.7045 | Val. Acc: 81.16% | Val. AUROC: 0.89 | Val. F1: 0.8127 | Val. AUPRC: 0.88\n",
      "Epoch 034: | Train Loss: 0.0869 | Train Acc: 97.08% | Train AUROC: 1.00 | Train F1: 0.9708 | Train AUPRC: 0.99 || Val. Loss: 0.7134 | Val. Acc: 79.62% | Val. AUROC: 0.89 | Val. F1: 0.8041 | Val. AUPRC: 0.89\n",
      "Epoch 035: | Train Loss: 0.0821 | Train Acc: 97.13% | Train AUROC: 1.00 | Train F1: 0.9713 | Train AUPRC: 1.00 || Val. Loss: 0.7339 | Val. Acc: 81.04% | Val. AUROC: 0.88 | Val. F1: 0.8174 | Val. AUPRC: 0.88\n",
      "Epoch 036: | Train Loss: 0.0808 | Train Acc: 97.20% | Train AUROC: 1.00 | Train F1: 0.9720 | Train AUPRC: 1.00 || Val. Loss: 0.6940 | Val. Acc: 80.21% | Val. AUROC: 0.88 | Val. F1: 0.8060 | Val. AUPRC: 0.87\n",
      "Epoch 037: | Train Loss: 0.0789 | Train Acc: 97.16% | Train AUROC: 1.00 | Train F1: 0.9716 | Train AUPRC: 1.00 || Val. Loss: 0.7316 | Val. Acc: 80.81% | Val. AUROC: 0.88 | Val. F1: 0.8129 | Val. AUPRC: 0.87\n",
      "Epoch 038: | Train Loss: 0.0784 | Train Acc: 96.99% | Train AUROC: 1.00 | Train F1: 0.9701 | Train AUPRC: 1.00 || Val. Loss: 0.7813 | Val. Acc: 80.81% | Val. AUROC: 0.88 | Val. F1: 0.8172 | Val. AUPRC: 0.87\n",
      "Epoch 039: | Train Loss: 0.0767 | Train Acc: 97.36% | Train AUROC: 1.00 | Train F1: 0.9737 | Train AUPRC: 1.00 || Val. Loss: 0.7634 | Val. Acc: 79.03% | Val. AUROC: 0.89 | Val. F1: 0.8036 | Val. AUPRC: 0.88\n",
      "Epoch 040: | Train Loss: 0.0761 | Train Acc: 97.16% | Train AUROC: 1.00 | Train F1: 0.9716 | Train AUPRC: 1.00 || Val. Loss: 0.7224 | Val. Acc: 81.28% | Val. AUROC: 0.88 | Val. F1: 0.8163 | Val. AUPRC: 0.88\n",
      "Epoch 041: | Train Loss: 0.0777 | Train Acc: 97.25% | Train AUROC: 1.00 | Train F1: 0.9725 | Train AUPRC: 1.00 || Val. Loss: 0.7171 | Val. Acc: 80.69% | Val. AUROC: 0.89 | Val. F1: 0.8120 | Val. AUPRC: 0.88\n",
      "Epoch 042: | Train Loss: 0.0692 | Train Acc: 97.53% | Train AUROC: 1.00 | Train F1: 0.9753 | Train AUPRC: 1.00 || Val. Loss: 0.7953 | Val. Acc: 79.27% | Val. AUROC: 0.88 | Val. F1: 0.8045 | Val. AUPRC: 0.88\n",
      "Epoch 043: | Train Loss: 0.0737 | Train Acc: 97.17% | Train AUROC: 1.00 | Train F1: 0.9717 | Train AUPRC: 1.00 || Val. Loss: 0.7540 | Val. Acc: 81.75% | Val. AUROC: 0.89 | Val. F1: 0.8184 | Val. AUPRC: 0.88\n",
      "Epoch 044: | Train Loss: 0.0725 | Train Acc: 97.44% | Train AUROC: 1.00 | Train F1: 0.9744 | Train AUPRC: 1.00 || Val. Loss: 0.7921 | Val. Acc: 79.38% | Val. AUROC: 0.88 | Val. F1: 0.8009 | Val. AUPRC: 0.87\n",
      "Epoch 045: | Train Loss: 0.0597 | Train Acc: 97.75% | Train AUROC: 1.00 | Train F1: 0.9775 | Train AUPRC: 1.00 || Val. Loss: 0.7435 | Val. Acc: 81.04% | Val. AUROC: 0.89 | Val. F1: 0.8152 | Val. AUPRC: 0.89\n",
      "Epoch 046: | Train Loss: 0.0715 | Train Acc: 97.54% | Train AUROC: 1.00 | Train F1: 0.9755 | Train AUPRC: 1.00 || Val. Loss: 0.7646 | Val. Acc: 80.57% | Val. AUROC: 0.88 | Val. F1: 0.8115 | Val. AUPRC: 0.88\n",
      "Epoch 047: | Train Loss: 0.0670 | Train Acc: 97.81% | Train AUROC: 1.00 | Train F1: 0.9781 | Train AUPRC: 1.00 || Val. Loss: 0.7556 | Val. Acc: 79.86% | Val. AUROC: 0.89 | Val. F1: 0.8055 | Val. AUPRC: 0.88\n",
      "Epoch 048: | Train Loss: 0.0563 | Train Acc: 98.15% | Train AUROC: 1.00 | Train F1: 0.9815 | Train AUPRC: 1.00 || Val. Loss: 0.8197 | Val. Acc: 80.21% | Val. AUROC: 0.88 | Val. F1: 0.8083 | Val. AUPRC: 0.88\n",
      "Epoch 049: | Train Loss: 0.0644 | Train Acc: 97.67% | Train AUROC: 1.00 | Train F1: 0.9768 | Train AUPRC: 1.00 || Val. Loss: 0.8055 | Val. Acc: 81.40% | Val. AUROC: 0.89 | Val. F1: 0.8210 | Val. AUPRC: 0.88\n",
      "Epoch 050: | Train Loss: 0.0684 | Train Acc: 97.67% | Train AUROC: 1.00 | Train F1: 0.9768 | Train AUPRC: 1.00 || Val. Loss: 0.7880 | Val. Acc: 80.81% | Val. AUROC: 0.88 | Val. F1: 0.8155 | Val. AUPRC: 0.88\n",
      "Epoch 051: | Train Loss: 0.0576 | Train Acc: 97.96% | Train AUROC: 1.00 | Train F1: 0.9796 | Train AUPRC: 1.00 || Val. Loss: 0.8085 | Val. Acc: 80.09% | Val. AUROC: 0.89 | Val. F1: 0.8060 | Val. AUPRC: 0.88\n",
      "Epoch 052: | Train Loss: 0.0607 | Train Acc: 97.93% | Train AUROC: 1.00 | Train F1: 0.9793 | Train AUPRC: 1.00 || Val. Loss: 0.8088 | Val. Acc: 81.16% | Val. AUROC: 0.88 | Val. F1: 0.8166 | Val. AUPRC: 0.88\n",
      "Epoch 053: | Train Loss: 0.0638 | Train Acc: 97.57% | Train AUROC: 1.00 | Train F1: 0.9757 | Train AUPRC: 1.00 || Val. Loss: 0.7970 | Val. Acc: 80.33% | Val. AUROC: 0.89 | Val. F1: 0.8092 | Val. AUPRC: 0.88\n",
      "Epoch 054: | Train Loss: 0.0627 | Train Acc: 97.75% | Train AUROC: 1.00 | Train F1: 0.9776 | Train AUPRC: 1.00 || Val. Loss: 0.7940 | Val. Acc: 80.92% | Val. AUROC: 0.88 | Val. F1: 0.8099 | Val. AUPRC: 0.88\n",
      "Epoch 055: | Train Loss: 0.0521 | Train Acc: 98.15% | Train AUROC: 1.00 | Train F1: 0.9815 | Train AUPRC: 1.00 || Val. Loss: 0.8280 | Val. Acc: 80.21% | Val. AUROC: 0.88 | Val. F1: 0.8078 | Val. AUPRC: 0.87\n",
      "Epoch 056: | Train Loss: 0.0589 | Train Acc: 98.02% | Train AUROC: 1.00 | Train F1: 0.9802 | Train AUPRC: 1.00 || Val. Loss: 0.8241 | Val. Acc: 79.98% | Val. AUROC: 0.88 | Val. F1: 0.8042 | Val. AUPRC: 0.88\n",
      "Epoch 057: | Train Loss: 0.0535 | Train Acc: 98.07% | Train AUROC: 1.00 | Train F1: 0.9808 | Train AUPRC: 1.00 || Val. Loss: 0.8557 | Val. Acc: 80.57% | Val. AUROC: 0.88 | Val. F1: 0.8111 | Val. AUPRC: 0.87\n",
      "Epoch 058: | Train Loss: 0.0570 | Train Acc: 98.21% | Train AUROC: 1.00 | Train F1: 0.9821 | Train AUPRC: 1.00 || Val. Loss: 0.7860 | Val. Acc: 80.92% | Val. AUROC: 0.88 | Val. F1: 0.8099 | Val. AUPRC: 0.88\n",
      "Epoch 059: | Train Loss: 0.0588 | Train Acc: 97.66% | Train AUROC: 1.00 | Train F1: 0.9766 | Train AUPRC: 1.00 || Val. Loss: 0.8242 | Val. Acc: 80.69% | Val. AUROC: 0.88 | Val. F1: 0.8034 | Val. AUPRC: 0.86\n",
      "Epoch 060: | Train Loss: 0.0601 | Train Acc: 97.72% | Train AUROC: 1.00 | Train F1: 0.9772 | Train AUPRC: 1.00 || Val. Loss: 0.9193 | Val. Acc: 79.03% | Val. AUROC: 0.88 | Val. F1: 0.8049 | Val. AUPRC: 0.88\n",
      "Epoch 061: | Train Loss: 0.0464 | Train Acc: 98.22% | Train AUROC: 1.00 | Train F1: 0.9822 | Train AUPRC: 1.00 || Val. Loss: 0.8212 | Val. Acc: 80.45% | Val. AUROC: 0.88 | Val. F1: 0.8066 | Val. AUPRC: 0.89\n",
      "Epoch 062: | Train Loss: 0.0515 | Train Acc: 98.24% | Train AUROC: 1.00 | Train F1: 0.9824 | Train AUPRC: 1.00 || Val. Loss: 0.8820 | Val. Acc: 79.86% | Val. AUROC: 0.88 | Val. F1: 0.8068 | Val. AUPRC: 0.88\n",
      "Epoch 063: | Train Loss: 0.0500 | Train Acc: 98.00% | Train AUROC: 1.00 | Train F1: 0.9800 | Train AUPRC: 1.00 || Val. Loss: 0.7877 | Val. Acc: 80.45% | Val. AUROC: 0.88 | Val. F1: 0.8070 | Val. AUPRC: 0.88\n",
      "Epoch 064: | Train Loss: 0.0625 | Train Acc: 97.57% | Train AUROC: 1.00 | Train F1: 0.9757 | Train AUPRC: 1.00 || Val. Loss: 0.8361 | Val. Acc: 79.86% | Val. AUROC: 0.88 | Val. F1: 0.8059 | Val. AUPRC: 0.88\n",
      "Epoch 065: | Train Loss: 0.0603 | Train Acc: 97.79% | Train AUROC: 1.00 | Train F1: 0.9780 | Train AUPRC: 1.00 || Val. Loss: 0.8393 | Val. Acc: 80.92% | Val. AUROC: 0.89 | Val. F1: 0.8117 | Val. AUPRC: 0.89\n",
      "Epoch 066: | Train Loss: 0.0536 | Train Acc: 98.03% | Train AUROC: 1.00 | Train F1: 0.9803 | Train AUPRC: 1.00 || Val. Loss: 0.8175 | Val. Acc: 80.21% | Val. AUROC: 0.89 | Val. F1: 0.8087 | Val. AUPRC: 0.89\n",
      "Epoch 067: | Train Loss: 0.0518 | Train Acc: 98.33% | Train AUROC: 1.00 | Train F1: 0.9833 | Train AUPRC: 1.00 || Val. Loss: 0.7936 | Val. Acc: 80.57% | Val. AUROC: 0.89 | Val. F1: 0.8106 | Val. AUPRC: 0.89\n",
      "Epoch 068: | Train Loss: 0.0502 | Train Acc: 98.28% | Train AUROC: 1.00 | Train F1: 0.9828 | Train AUPRC: 1.00 || Val. Loss: 0.8343 | Val. Acc: 81.40% | Val. AUROC: 0.88 | Val. F1: 0.8111 | Val. AUPRC: 0.88\n",
      "Epoch 069: | Train Loss: 0.0535 | Train Acc: 98.15% | Train AUROC: 1.00 | Train F1: 0.9815 | Train AUPRC: 1.00 || Val. Loss: 0.8095 | Val. Acc: 81.28% | Val. AUROC: 0.89 | Val. F1: 0.8150 | Val. AUPRC: 0.89\n",
      "Epoch 070: | Train Loss: 0.0458 | Train Acc: 98.47% | Train AUROC: 1.00 | Train F1: 0.9848 | Train AUPRC: 1.00 || Val. Loss: 0.8354 | Val. Acc: 81.40% | Val. AUROC: 0.89 | Val. F1: 0.8189 | Val. AUPRC: 0.89\n",
      "Epoch 071: | Train Loss: 0.0473 | Train Acc: 98.43% | Train AUROC: 1.00 | Train F1: 0.9843 | Train AUPRC: 1.00 || Val. Loss: 0.8203 | Val. Acc: 82.23% | Val. AUROC: 0.89 | Val. F1: 0.8268 | Val. AUPRC: 0.89\n",
      "Epoch 072: | Train Loss: 0.0512 | Train Acc: 98.33% | Train AUROC: 1.00 | Train F1: 0.9833 | Train AUPRC: 1.00 || Val. Loss: 0.7992 | Val. Acc: 81.87% | Val. AUROC: 0.89 | Val. F1: 0.8202 | Val. AUPRC: 0.89\n",
      "Epoch 073: | Train Loss: 0.0540 | Train Acc: 97.93% | Train AUROC: 1.00 | Train F1: 0.9793 | Train AUPRC: 1.00 || Val. Loss: 0.8529 | Val. Acc: 80.69% | Val. AUROC: 0.88 | Val. F1: 0.8107 | Val. AUPRC: 0.88\n",
      "Epoch 074: | Train Loss: 0.0452 | Train Acc: 98.62% | Train AUROC: 1.00 | Train F1: 0.9862 | Train AUPRC: 1.00 || Val. Loss: 0.8042 | Val. Acc: 80.81% | Val. AUROC: 0.89 | Val. F1: 0.8094 | Val. AUPRC: 0.89\n",
      "Epoch 075: | Train Loss: 0.0401 | Train Acc: 98.62% | Train AUROC: 1.00 | Train F1: 0.9863 | Train AUPRC: 1.00 || Val. Loss: 0.8315 | Val. Acc: 79.86% | Val. AUROC: 0.89 | Val. F1: 0.8068 | Val. AUPRC: 0.90\n",
      "Epoch 076: | Train Loss: 0.0453 | Train Acc: 98.37% | Train AUROC: 1.00 | Train F1: 0.9837 | Train AUPRC: 1.00 || Val. Loss: 0.8919 | Val. Acc: 80.33% | Val. AUROC: 0.88 | Val. F1: 0.8047 | Val. AUPRC: 0.88\n",
      "Epoch 077: | Train Loss: 0.0482 | Train Acc: 98.15% | Train AUROC: 1.00 | Train F1: 0.9816 | Train AUPRC: 1.00 || Val. Loss: 0.8654 | Val. Acc: 80.57% | Val. AUROC: 0.89 | Val. F1: 0.8102 | Val. AUPRC: 0.88\n",
      "Epoch 078: | Train Loss: 0.0421 | Train Acc: 98.49% | Train AUROC: 1.00 | Train F1: 0.9849 | Train AUPRC: 1.00 || Val. Loss: 0.9049 | Val. Acc: 81.28% | Val. AUROC: 0.89 | Val. F1: 0.8196 | Val. AUPRC: 0.88\n",
      "Epoch 079: | Train Loss: 0.0535 | Train Acc: 98.18% | Train AUROC: 1.00 | Train F1: 0.9818 | Train AUPRC: 1.00 || Val. Loss: 0.8688 | Val. Acc: 81.52% | Val. AUROC: 0.89 | Val. F1: 0.8219 | Val. AUPRC: 0.88\n",
      "Epoch 080: | Train Loss: 0.0383 | Train Acc: 98.67% | Train AUROC: 1.00 | Train F1: 0.9867 | Train AUPRC: 1.00 || Val. Loss: 0.9325 | Val. Acc: 79.38% | Val. AUROC: 0.89 | Val. F1: 0.8049 | Val. AUPRC: 0.89\n",
      "Epoch 081: | Train Loss: 0.0420 | Train Acc: 98.49% | Train AUROC: 1.00 | Train F1: 0.9849 | Train AUPRC: 1.00 || Val. Loss: 0.8680 | Val. Acc: 81.16% | Val. AUROC: 0.89 | Val. F1: 0.8183 | Val. AUPRC: 0.89\n",
      "Epoch 082: | Train Loss: 0.0511 | Train Acc: 98.28% | Train AUROC: 1.00 | Train F1: 0.9829 | Train AUPRC: 1.00 || Val. Loss: 0.8551 | Val. Acc: 80.21% | Val. AUROC: 0.89 | Val. F1: 0.8069 | Val. AUPRC: 0.89\n",
      "Epoch 083: | Train Loss: 0.0446 | Train Acc: 98.43% | Train AUROC: 1.00 | Train F1: 0.9843 | Train AUPRC: 1.00 || Val. Loss: 0.8768 | Val. Acc: 80.21% | Val. AUROC: 0.89 | Val. F1: 0.8104 | Val. AUPRC: 0.89\n",
      "Epoch 084: | Train Loss: 0.0402 | Train Acc: 98.52% | Train AUROC: 1.00 | Train F1: 0.9852 | Train AUPRC: 1.00 || Val. Loss: 0.9105 | Val. Acc: 79.98% | Val. AUROC: 0.88 | Val. F1: 0.8077 | Val. AUPRC: 0.88\n",
      "Epoch 085: | Train Loss: 0.0508 | Train Acc: 98.06% | Train AUROC: 1.00 | Train F1: 0.9806 | Train AUPRC: 1.00 || Val. Loss: 0.8680 | Val. Acc: 82.11% | Val. AUROC: 0.88 | Val. F1: 0.8209 | Val. AUPRC: 0.89\n",
      "Epoch 086: | Train Loss: 0.0461 | Train Acc: 98.31% | Train AUROC: 1.00 | Train F1: 0.9831 | Train AUPRC: 1.00 || Val. Loss: 0.8955 | Val. Acc: 79.98% | Val. AUROC: 0.89 | Val. F1: 0.8082 | Val. AUPRC: 0.89\n",
      "Epoch 087: | Train Loss: 0.0495 | Train Acc: 98.21% | Train AUROC: 1.00 | Train F1: 0.9821 | Train AUPRC: 1.00 || Val. Loss: 0.8172 | Val. Acc: 80.81% | Val. AUROC: 0.89 | Val. F1: 0.8138 | Val. AUPRC: 0.90\n",
      "Epoch 088: | Train Loss: 0.0421 | Train Acc: 98.43% | Train AUROC: 1.00 | Train F1: 0.9844 | Train AUPRC: 1.00 || Val. Loss: 0.8698 | Val. Acc: 80.69% | Val. AUROC: 0.89 | Val. F1: 0.8150 | Val. AUPRC: 0.89\n",
      "Epoch 089: | Train Loss: 0.0453 | Train Acc: 98.31% | Train AUROC: 1.00 | Train F1: 0.9831 | Train AUPRC: 1.00 || Val. Loss: 0.8856 | Val. Acc: 81.52% | Val. AUROC: 0.89 | Val. F1: 0.8215 | Val. AUPRC: 0.89\n",
      "Epoch 090: | Train Loss: 0.0384 | Train Acc: 98.64% | Train AUROC: 1.00 | Train F1: 0.9864 | Train AUPRC: 1.00 || Val. Loss: 0.8362 | Val. Acc: 81.40% | Val. AUROC: 0.89 | Val. F1: 0.8185 | Val. AUPRC: 0.89\n",
      "Epoch 091: | Train Loss: 0.0389 | Train Acc: 98.71% | Train AUROC: 1.00 | Train F1: 0.9871 | Train AUPRC: 1.00 || Val. Loss: 0.9061 | Val. Acc: 80.69% | Val. AUROC: 0.89 | Val. F1: 0.8150 | Val. AUPRC: 0.88\n",
      "Epoch 092: | Train Loss: 0.0495 | Train Acc: 98.31% | Train AUROC: 1.00 | Train F1: 0.9831 | Train AUPRC: 1.00 || Val. Loss: 0.8675 | Val. Acc: 80.92% | Val. AUROC: 0.89 | Val. F1: 0.8099 | Val. AUPRC: 0.89\n",
      "Epoch 093: | Train Loss: 0.0409 | Train Acc: 98.61% | Train AUROC: 1.00 | Train F1: 0.9861 | Train AUPRC: 1.00 || Val. Loss: 0.8655 | Val. Acc: 82.23% | Val. AUROC: 0.89 | Val. F1: 0.8248 | Val. AUPRC: 0.89\n",
      "Epoch 094: | Train Loss: 0.0362 | Train Acc: 98.83% | Train AUROC: 1.00 | Train F1: 0.9883 | Train AUPRC: 1.00 || Val. Loss: 0.9208 | Val. Acc: 81.16% | Val. AUROC: 0.89 | Val. F1: 0.8179 | Val. AUPRC: 0.89\n",
      "Epoch 095: | Train Loss: 0.0365 | Train Acc: 98.62% | Train AUROC: 1.00 | Train F1: 0.9862 | Train AUPRC: 1.00 || Val. Loss: 0.9320 | Val. Acc: 79.98% | Val. AUROC: 0.88 | Val. F1: 0.8090 | Val. AUPRC: 0.88\n",
      "Epoch 096: | Train Loss: 0.0409 | Train Acc: 98.65% | Train AUROC: 1.00 | Train F1: 0.9866 | Train AUPRC: 1.00 || Val. Loss: 0.9135 | Val. Acc: 81.40% | Val. AUROC: 0.89 | Val. F1: 0.8197 | Val. AUPRC: 0.89\n",
      "Epoch 097: | Train Loss: 0.0406 | Train Acc: 98.59% | Train AUROC: 1.00 | Train F1: 0.9860 | Train AUPRC: 1.00 || Val. Loss: 0.9060 | Val. Acc: 80.45% | Val. AUROC: 0.88 | Val. F1: 0.8088 | Val. AUPRC: 0.89\n",
      "Epoch 098: | Train Loss: 0.0436 | Train Acc: 98.64% | Train AUROC: 1.00 | Train F1: 0.9864 | Train AUPRC: 1.00 || Val. Loss: 0.8655 | Val. Acc: 79.74% | Val. AUROC: 0.89 | Val. F1: 0.8014 | Val. AUPRC: 0.89\n",
      "Epoch 099: | Train Loss: 0.0406 | Train Acc: 98.50% | Train AUROC: 1.00 | Train F1: 0.9850 | Train AUPRC: 1.00 || Val. Loss: 0.9248 | Val. Acc: 79.03% | Val. AUROC: 0.88 | Val. F1: 0.7977 | Val. AUPRC: 0.88\n",
      "Epoch 100: | Train Loss: 0.0429 | Train Acc: 98.33% | Train AUROC: 1.00 | Train F1: 0.9833 | Train AUPRC: 1.00 || Val. Loss: 0.9105 | Val. Acc: 79.86% | Val. AUROC: 0.89 | Val. F1: 0.8019 | Val. AUPRC: 0.89\n",
      "Test Loss: 0.4684 | Test Acc: 78.93% | Test AUROC: 0.87 | Test F1: 0.8074 | Test AUPRC: 0.88\n"
     ]
    }
   ],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Positive : Negative ratio|F1 score|AUPRC score|\n",
    "|-----|-----|-----|\n",
    "|1:1|0.79|0.87| \n",
    "|1:2|0.74|0.83|\n",
    "|1:3|0.68|0.77|\n",
    "|1:6|0.66|0.74|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class imbalance 문제를 좀 개선하는 방법이 있으면 그걸 novelty로 추가?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ayn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4698125b34f9b3056e7b596654ef06bea4fe54a8b707ab96252cf01711dc60f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
